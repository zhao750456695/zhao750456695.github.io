<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习," />





  <link rel="alternate" href="/atom.xml" title="FinGeek<http://zhaojie.tech>" type="application/atom+xml" />






<meta name="description" content="你问我资瓷不资瓷，我当然资瓷向量机。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="传统机器学习算法巅峰之作：SVM">
<meta property="og:url" content="http://yoursite.com/post/bc66df1b.html">
<meta property="og:site_name" content="FinGeek&lt;http:&#x2F;&#x2F;zhaojie.tech&gt;">
<meta property="og:description" content="你问我资瓷不资瓷，我当然资瓷向量机。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-07-24T05:05:14.032Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="传统机器学习算法巅峰之作：SVM">
<meta name="twitter:description" content="你问我资瓷不资瓷，我当然资瓷向量机。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/post/bc66df1b.html"/>





  <title>传统机器学习算法巅峰之作：SVM | FinGeek<http://zhaojie.tech></title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">FinGeek<http://zhaojie.tech></span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/post/bc66df1b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JieZhao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FinGeek<http://zhaojie.tech>">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">传统机器学习算法巅峰之作：SVM</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-23T16:06:53+08:00">
                2018-07-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  你问我资瓷不资瓷，我当然资瓷向量机。
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="SVM建模"><a href="#SVM建模" class="headerlink" title="SVM建模"></a>SVM建模</h1><p>线性分类器和最优线性分类器</p>
<p>样本空间中，我们想找到切分超平面来区分样本$w^Tx+b=0$,w是法向量，b是偏移。</p>
<p>$f(x)=sign(w^T+b)$</p>
<p>$||X||_2=\sqrt{\sum^n\limits_{i=1}|X_i|^2}=X^T X$</p>
<p>点到平面的距离</p>
<p>超平面$H=\{ w^Tx+b=0 \}$</p>
<p>空间中任意一点P到平面的距离为</p>
<script type="math/tex; mode=display">r= \frac{w^T p+b}{\Vert w\Vert_2}</script><p>证明：</p>
<p>$P-P*$垂直于H</p>
<p>w是超平面的法向量，因此也垂直于H</p>
<p>于是，$P-P^* = \alpha w$  </p>
<p>两边同时乘以$w^T$</p>
<p>$w^T(P-P^*)=\alpha w^Tw$</p>
<p>而$w^Tw=\Vert w \Vert _2^2$</p>
<p>$p^<em>$在超平面上，所以有$w^T p^</em>= -b$</p>
<p>所以有，$w^T-b=\Vert w \Vert _2^2$</p>
<p>于是， $\alpha = \frac{w^TP+b}{\Vert w \Vert _2^2}$</p>
<p>P到$P^<em>$的距离为$\Vert P-P^</em> \Vert_2=\vert \alpha \vert \Vert w \Vert _2$</p>
<p>即：</p>
<p>$\Vert P-P^* \Vert_2=\vert \alpha \vert \Vert w \Vert _2= \frac{\vert w^T+b \vert}{\Vert w \Vert _2^2} \Vert w \Vert= \frac{\vert w^T+b \vert}{\Vert w \Vert_2}$</p>
<p>SVM目标函数</p>
<p>最小距离最大化</p>
<p>样本到超平面的距离</p>
<p>几何间隔</p>
<p>$M= \min\limits_i r_i = \min\limits_i \frac{\vert w^Tx_i +b \vert}{\Vert w \Vert_2}$</p>
<p>超平面用来分隔样本，我们希望样本到超平面的这个距离越大越好</p>
<p>所以，SVM目标函数是</p>
<p>$\max\limits_{w, b}M$</p>
<p>即</p>
<p>$\max\limits_{w, b}\{ \min\limits_{i} \frac{\vert w^Tx_i+b \vert}{\Vert w\Vert _2}\}$</p>
<p>外面的最大化是对参数而言的，里面的最小化是对样本而言的</p>
<p>分子有个绝对值十分麻烦，我们可以考虑把它去掉</p>
<p>分子部分可以改写成$y_i (w^T x_i =b)$</p>
<p>于是，目标函数变为 $\max\limits_{w,b}\{ \frac{1}{\Vert w \Vert_2}\min\limits_{i} y_i(w^T x_i +b)\}$</p>
<p>我们发现，将w和b同时变化k倍，距离不变：</p>
<p>$\frac{y_i(w^Tx_i+b)}{\Vert w\Vert _2}=\frac{y_i(kw^Tx_i+kb)}{\Vert kw \Vert_2 }$</p>
<p>上下是可以约掉的。</p>
<p>因此，为了方便，我们可以设计样本点到超平面的最小距离是1：</p>
<p>$y_i(w^Tx_i+b)=1$</p>
<p>同时有所有点都大于等于1</p>
<p>$y_i(w^Tx_i +b)\ge1,i=1,2,…,N$</p>
<p>这个条件是我们将最小距离变为1之后必须要满足的，因此作为约束条件。</p>
<p>综上，得到SVM基本模型：</p>
<script type="math/tex; mode=display">
\begin{align*}
&\min\limits_{w,b} \frac{1}{2}\Vert w \Vert _2^2\\
subject \quad to \quad &y_i(w^Tx_i +b)\ge1,i=1,2,...,N
\end{align*}</script><h1 id="SVM求解"><a href="#SVM求解" class="headerlink" title="SVM求解"></a>SVM求解</h1><p>我们前面知道QP问题是凸优化问题，QP问题的标准型如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
&minimize \quad \frac{1}{2}X^TPX+C^TX+d\\
&subject\quad to\quad GX\le h\\
&\qquad \qquad \qquad AX=b
\end{align*}</script><p>下面的形式可以转化为上面的标准形式：</p>
<script type="math/tex; mode=display">
\begin{align*}
&minimize\quad \frac{1}{2}\Vert w \Vert_2^2 +C\sum\limits_{i=1}^N\xi_i\\
&subject\quad to\quad y_i(w^Tx_i+b)\ge1-\xi_i,i=1,2,...,m\\
&\qquad \qquad \qquad \xi_i\ge0
\end{align*}</script><p>当</p>
<p>上式$C=0,\xi=0$时，就是SVM基本模型的目标函数，于是我们就可以解除w和b，但是当样本量非常大的时候，解的速度非常慢。</p>
<h2 id="SVM对偶问题"><a href="#SVM对偶问题" class="headerlink" title="SVM对偶问题"></a>SVM对偶问题</h2><p>上面的原问题可以QP问题的常规解法解决，也可以通过求解对偶问题求得最优解，这样做的优点有：一是对偶问题往往更容易求解；二是自然引入核函数，进而推广到非线性分类问题。</p>
<p>拉格朗日函数</p>
<script type="math/tex; mode=display">
L(w,b, \lambda)=\frac{1}{2}\Vert w\Vert_2 +\sum\limits_{i=1}^n\lambda_i(1-y_i(w^Tx_i+b))</script><p>则有拉格朗日对偶函数</p>
<p>$d^*=\max\limits_{\lambda\ge0}(\min\limits_{w,b}L(w,b,\lambda))$</p>
<p>令$L(w,b,\lambda)$对$\lambda$和b偏导为0，则有：</p>
<p>$w=\sum\limits_{i=1}^N\lambda_iy_ix_i$和$\sum\limits_{i=1}^N\lambda_iy_i=0$</p>
<p>上面相当于求了对偶函数内层的最小值，将它们带入内层，对偶函数变为：</p>
<p>$\max\limits_\lambda \sum\limits_{i=1}^N\lambda_i-\frac{1}{2}\sum\limits_{i=1}^N\sum\limits_{j=1}^N\lambda_i\lambda_jy_iy_jx_i^Tx_j$</p>
<p>$subject \quad to\quad \sum\limits_{i=1}^N\lambda_iy_i=0,\lambda_i\ge0,i=1,2,…,N$</p>
<p>这仍是QP问题，仍有N个约束，但是有个快速解法SMO，样本数多的时候也可以很快解决。</p>
<h2 id="KKT"><a href="#KKT" class="headerlink" title="KKT"></a>KKT</h2><p>假定能解除$\lambda^*$，强对偶，根据KKT有：</p>
<script type="math/tex; mode=display">
y_i(w^{*T}x_i+b^*)\ge1\\
\lambda^*\ge0\\
\lambda^*(y_i(w^{*T}x_i+b^*)-1)=0\\
w=\sum\limits_{i=1}^N\lambda_i^*y_ix_i ,\quad \sum\limits_{i=1}^N\lambda_i^*y_i=0</script><h2 id="SVM最终步骤"><a href="#SVM最终步骤" class="headerlink" title="SVM最终步骤"></a>SVM最终步骤</h2><p>最优分离超平面：</p>
<script type="math/tex; mode=display">
w^{*T}x+b^*=0\\
\sum\limits_{i=1}^N\lambda^*y_ix_i^T+b^*=0</script><p>决策函数：</p>
<p>$f(x)=sign(\sum\limits_{i=1}^N\lambda_i^*y_ix_i^Tx+b)$</p>
<h2 id="SMO求解-lambda"><a href="#SMO求解-lambda" class="headerlink" title="SMO求解$\lambda^*$"></a>SMO求解$\lambda^*$</h2><p>选取一对需要更新的变量$\lambda_i$和$\lambda_j$，固定其它参数，求解SVM的对偶形式，得到$\lambda_i$和$\lambda_j$，每次求解都是关于$\lambda_i$的单变量QP问题，仅有约束$\lambda_i\ge0$.</p>
<h1 id="SVM扩展"><a href="#SVM扩展" class="headerlink" title="SVM扩展"></a>SVM扩展</h1><p>前面的推导，都是基于样本点线性可分，而这往往是不现实的。</p>
<h2 id="线性支持向量机与软间隔"><a href="#线性支持向量机与软间隔" class="headerlink" title="线性支持向量机与软间隔"></a>线性支持向量机与软间隔</h2><p>线性可分问题的支持向量机学习方法，对线性不可分训练数据是不适用的，因为这是上述方法的不等式约束不能成立。线性不可分意味着某些样本点不能满足<strong>函数间隔</strong>大于等于1的约束条件。比如二维平面上，样本点混合在一起，你根本无法找到一条线，使样本点在线的两边。这时咋办呢？我们可以放松约束，对每个样本点$(x_i,y_i)$引进一个松弛变量$\xi_i\ge0$,使函数间隔加上松弛变量大于等于1。相当于把混在一起的样本点推开一些，使其不那么混乱亦或是我们变的宽容了，可以允许一些错误的分类点。</p>
<p>我们也不能无限宽容，我们有做个有底线的好人，否则只能不叫宽容叫怂，好吧，戏加太多了。于是，对每个松弛变量$\xi_i$，支付一个代价$\xi_i$。</p>
<p>综上，线性不可分的线性支持向量机的学习问题变成如下凸二次规划问题（原始问题）：</p>
<script type="math/tex; mode=display">
\min\limits_{w,b,\xi}\quad\frac{1}{2}\Vert w \Vert^2+C\sum\limits_{i=1}^N\xi_i\\
s.t.\quad y_i(wx_i+ b)\ge1-\xi_i\\
\quad \xi_i\ge0,i=1,2,...,N</script><p>C&gt;0,成为惩罚参数，一般有应用问题决定，C值大时对误分类的惩罚增大，C值小时对误分类的惩罚减小。</p>
<p>我们将软间隔最大化问题得到的超平面$w^<em>x+b^</em>=0$以及相应的分类决策函数$f(x)=sign(w^<em>x+b^</em>)$称为线性支持向量机。</p>
<p>显然，线性支持向量机包括线性可分向量机，也就是说线性可分向量机和线性不可分向量机都是线性支持向量机。</p>
<p>我们依然可以将上面的原问题转为对偶问题求解，对偶问题的形式如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
&\min\limits_\alpha\frac{1}{2}\sum\limits_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j(x_ix_j)-\sum\limits_{i=1}^N\alpha_i\\
&s.t.\quad\sum\limits_{i=1}^N\alpha_iy_i=0\\
&\qquad \quad0\le \alpha_i\le C,\quad i=1,2,...,N
\end{align*}</script><p>下面是推导过程;</p>
<p>原始问题的拉格朗日函数是</p>
<script type="math/tex; mode=display">
L(w,b,\xi,\alpha,\mu)=\frac{1}{2}\Vert w\Vert _2+C\sum_{i=1}^N\xi_i-\sum_{i=1}^N\alpha_i(y_i(wx_i+b)-1+\xi_i)-\sum_{i=1}^N\mu_i\xi_i,\alpha_i\ge0,\mu_i\ge0</script><p>上面主问题可以写成极小极大的形式，而拉格朗日对偶问题是拉格朗日函数的极大极小问题。</p>
<p>首先求$L(w,b,\xi,\alpha,\mu)$对$w,b,\xi$的极小，由</p>
<script type="math/tex; mode=display">
\nabla _wL(w,b,\xi,\alpha,\mu)=w-\sum\limits_{i=1}^n\alpha_iy_ix_i=0\\
\nabla_bL(w,b,\xi,\alpha,\mu)=-\sum\limits_{i=1}^N\alpha_iy_i=0\\
\nabla_{\xi_i}L(w,b,\xi,\alpha,\mu)=C-\alpha_i-\mu_i=0</script><p>得</p>
<script type="math/tex; mode=display">
w=\sum_{i=1}^N\alpha_iy_ix_i\\
\sum\limits_{i=1}^N\alpha_iy_i=0\\
C-\alpha_i-\mu_i=0</script><p>将上面三式代入拉格朗日主问题得：</p>
<script type="math/tex; mode=display">
\min\limits_{w,b,\xi}L(w,b,\xi,\alpha,\mu)=-\frac{1}{2}\sum\limits_{i=1}^N\sum\limits_{j=1}^N\alpha_i
\alpha_jy_iy_j(x_ix_j)+\sum\limits_{i=1}^N\alpha_i</script><p>再对$\min\limits_{w,b,\xi}L(w,b,\xi,\alpha,\mu)$求$\alpha$的极大,即得对偶问题：</p>
<script type="math/tex; mode=display">
\max\limits_{\alpha}-\frac{1}{2}\sum\limits_{i=1}^N\sum\limits_{j=1}^N\alpha_i\alpha_jy_iy_j(x_ix_j)+\sum\limits_{i=1}^N\alpha_i\\
s.t.\quad\sum\limits_{i=1}^N\alpha_iy_i=0\\
C-\alpha_i-\mu_i=0\\
\alpha_i\ge0\\
\mu_i\ge0,i=1,2,...,N</script><p>上面的约束利用约束第二个等式消去$\mu_i$，从而只留下变量$\alpha_i$，约束后三个式子可以转为$0\le \alpha_i \le C$再将目标函数转为求极小。</p>
<p>于是，我们得到了上面所说的对偶问题的形式：</p>
<script type="math/tex; mode=display">
\begin{align*}
&\min\limits_\alpha\frac{1}{2}\sum\limits_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j(x_ix_j)-\sum\limits_{i=1}^N\alpha_i\\
&s.t.\quad\sum\limits_{i=1}^N\alpha_iy_i=0\\
&\qquad \quad0\le \alpha_i\le C,\quad i=1,2,...,N
\end{align*}</script><p>从上面的形式，我们可以得到最优化问题的解：$\alpha^<em>=(\alpha^</em>_1,\alpha^<em>_2,…,\alpha^</em>_l)^T$,根据KKT条件，可以得到：</p>
<script type="math/tex; mode=display">
w^*=\sum\limits_{i=1}^N\alpha_i^*y_ix_i\\
b^*=y_j-\sum\limits_{i=1}^N\alpha^*_iy_i(x_ix_j)</script><h2 id="非线性支持向量机与核函数"><a href="#非线性支持向量机与核函数" class="headerlink" title="非线性支持向量机与核函数"></a>非线性支持向量机与核函数</h2><p>用线性分类方法求解非线性问题分为两步：首先使用一个变换将原空间的数据映射到新的空间；然后再新的空间里用线性分类学习方法从训练数据集中学习分类模型。</p>
<p>核技巧就是这样一种方法，其基本想法是通过一个非线性变换将输入空间对应于一个特征空间，使得在输入空间中的超曲面模型对应于特征空间中的超平面模型。这样，分类问题的学习任务通过再特征空间中求解线性支持向量机就可以完成。</p>
<p>令$\phi(x)$表示将x映射后的特征向量，于是，在特征空间中划分超平面所对应的模型可表示为</p>
<script type="math/tex; mode=display">
f(x)=w^T\phi(x)+b</script><p>所以原问题变为：</p>
<script type="math/tex; mode=display">
\min\limits_{w,b}\frac{1}{2}\Vert w\Vert^2\\
s.t.\quad y_i(w^T\phi(x)+b)\ge1,i=1,2,...,m.</script><p>其对偶问题是</p>
<script type="math/tex; mode=display">
\max\limits_\alpha\sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_j\phi(x_i)^T\phi(x_j)\\
s.t.\quad\sum_{i=1}^m\alpha_iy_i=0,\\
\alpha_i\ge0,i=1,2,...,m.</script><p>求解上式，涉及到计算$\phi(x_i)$和$\phi(x_j)$,这是样本$x_i$和$x_j$映射到特征空间之后的内积，由于特征空间维数可能很高，甚至是无穷维，因此直接计算$\phi(x_i)$和$\phi(x_j)$通常是非常困难的。为了避开这个障碍，可以设想这样一个函数：</p>
<script type="math/tex; mode=display">
k(x_i,x_j)=\langle \phi(x_i),\phi(x_j)\rangle = \phi(x_i)^T \phi(x_j),</script><p>这个函数我们称之为核函数。</p>
<p> 此时，不必再去计算高维甚至无穷维特征空间中的内积。</p>
<p>也就是说这个核函数可以写成两个映射的内积，我们只要找到可以写成映射内积的函数就好了。</p>
<p>很棒的是，已经有关于核函数的定理，只要一个对称函数所对应的核矩阵半正定，它就能作为核函数使用。事实上，对于一个半正定核矩阵，总能找到一个与之对应的映射$\phi$。</p>
<p>常用的核函数有线性核，多项式核，高斯核，拉普拉斯核，Sigmoid核。</p>

      
    </div>
    
    
    
	<div>
	
	<div>

    <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>

</div>
	
	</div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/post/svm1.html" rel="next" title="svm前奏：凸优化对偶理论">
                <i class="fa fa-chevron-left"></i> svm前奏：凸优化对偶理论
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/post/d87f7e0c.html" rel="prev" title="test">
                test <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JieZhao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM建模"><span class="nav-number">1.</span> <span class="nav-text">SVM建模</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM求解"><span class="nav-number">2.</span> <span class="nav-text">SVM求解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM对偶问题"><span class="nav-number">2.1.</span> <span class="nav-text">SVM对偶问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KKT"><span class="nav-number">2.2.</span> <span class="nav-text">KKT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM最终步骤"><span class="nav-number">2.3.</span> <span class="nav-text">SVM最终步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO求解-lambda"><span class="nav-number">2.4.</span> <span class="nav-text">SMO求解$\lambda^*$</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM扩展"><span class="nav-number">3.</span> <span class="nav-text">SVM扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性支持向量机与软间隔"><span class="nav-number">3.1.</span> <span class="nav-text">线性支持向量机与软间隔</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#非线性支持向量机与核函数"><span class="nav-number">3.2.</span> <span class="nav-text">非线性支持向量机与核函数</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JieZhao</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  








  
  





  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_sphere.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
<!-- 页面点击小红心 --> 
<script type="text/javascript" src="/js/src/love.js"></script>